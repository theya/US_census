---
title: "US Census: Savings prediction"
author: "Molina Rafidison"
date: "June 15, 2016"
output: 
    html_document:
        keep_md: yes
---

# Introduction

## Introduction

This analysis aims to identify which people in the test dataset won more or less than $50,000 per year. 

## Preliminaries

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

### Reproducibility

Set the following seed to make sure the analysis is reproducible.

```{r}
seed <- 201606
```

Load the needed packages and install them if `FALSE`.

```{r packages, message = FALSE}
packages <- c("ggplot2", "tabplot", "caret", "plyr", "dplyr")
sapply(packages, require, character.only = TRUE, quietly = TRUE)
```

### Getting and reading data

Download [the Internet-based file](http://thomasdata.s3.amazonaws.com/ds/us_census_full.zip) and read data.

```{r}
## Set path
path <- getwd()

## Download directory
if (!file.exists("us_census_full")) {
    fileUrl <- "http://thomasdata.s3.amazonaws.com/ds/us_census_full.zip"
    tempFile <- "Dataset.zip"
    download.file(fileUrl, file.path(path, tempFile))
    ## Unzipping
    unzip(file.path(path, tempFile))
    ## Deleting temporary compressed file
    unlink(tempFile)
}

## Read data
train <- read.csv(file.path(path, "us_census_full/census_income_learn.csv"), 
                  na.strings = c("NA", "#DIV/0!", ""))
test <- read.csv(file.path(path, "us_census_full/census_income_test.csv"), 
                 na.strings = c("NA", "#DIV/0!", ""))
info <- read.csv(file.path(path, "us_census_full/census_income_metadata.txt"),
                 header = FALSE)
```

Get an idea of the datasets dimensions.

```{r}
dim(train); dim(test)
```

### Rename variables

The variables names are all messed up. I would like them to match the ones we can read on the text files. This will simplify the exploration and manipulation later on.

```{r}
varName <- gsub("[\\(\\)]", "", regmatches(info[89:128, ], gregexpr("\\(.*?\\)", info[89:128, ])))
varName <- gsub(" ", "\\.", varName)

replaceName <- function(data) {
    dataName <- names(data)
    dataName[25] <- "instance.weight"
    dataName[42] <- "incomes"
    dataName[-c(25, 42)] <- varName
    return(dataName)
}

names(train) <- replaceName(train); names(test) <- replaceName(test)
```

### Adding missing values

We have some `?` and `Not in universe` in the data. In my context, I will just replace them with NAs and work on them if need be along with the analysis.

```{r}
misVal <- function(data) {
    dataList <- lapply(data, function(x) {gsub("\\?|Not in universe *.*", NA, x)})
    data <- as.data.frame(dataList)
    return(data)
}

train <- misVal(train); test <- misVal(test)
```

## Reviewing classes

Because of the previous change, I need to rewrite some of the variables' class. 

```{r}
contiVar <- c(1, 6, 17, 18, 19, 31, 40)
train[, contiVar] <- apply(train[, contiVar], 2, function(x) {as.integer(as.character(x))})
test[, contiVar] <- apply(test[, contiVar], 2, function(x) {as.integer(as.character(x))})
```

### Basic summary

Here we go with this data:

```{r}
summary(train)
```

# Cleaning data

## Engineering features

For the purpose of this exercise and given the short timeframe, we will work only on a few variables. The analysis could be more thorough with further feature engineering though.
I also have to think that the following manipulations will have to appear on the test dataset too to properly train my models.

### Main outcome

The outcome `incomes` is a factor with two levels. Let's clean up its levels.

```{r}
cleanIncome <- function(curVar) {
    sapply(curVar, function(x) {
        if (x == " 50000+.") {
            curVar <- "50k+" 
        } else {
            curVar <- "-50k"
        }
    })
}

train$incomes <- cleanIncome(train$incomes)
train$incomes <- factor(train$incomes)

test$incomes <- cleanIncome(test$incomes)
test$incomes <- factor(test$incomes)
```

### Slicing ages

Let's look at the `age` variable. 

```{r}
ggplot(train, aes(x = incomes, y = age, group = incomes)) + 
    geom_boxplot() +
    labs(title = "Annual incomes according to age",
         x = "Annual incomes",
         y = "Age") 
```

I create five levels to convert the `age` variable into a factor.

```{r}
sliceAge <- function(curVar, newVar) {
    sapply(curVar, function(x) {
        if (x < 16) {
            newVar <- "Child"
        } else if (x %in% 16:33) {
            newVar <- "Young adult"
        } else if (x %in% 34:52) {
            newVar <- "Adult"
        } else if (x %in% 53:64) {
            newVar <- "Senior adult"
        } else {
            newVar <- "Oldest"
        }
    })
}

train$ageType <- factor(sliceAge(train$age, train$ageType))
test$ageType <- factor(sliceAge(test$age, test$ageType))
```

### Giving degrees

Let's see how education impact the incomes. 

```{r}
ggplot(train, aes(x = education, fill = incomes)) + 
    geom_bar() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    xlab("Education") +
    ylab("Count") +
    ggtitle("Impact of education on incomes")
```

It might be interesting to create a variable that tells whether a person has a degree or not while keeping those who went to college and got no degree.

```{r}
sortDegree <- function(curVar, newVar) {
    noDegree <- levels(train$education)[c(1:7, 11, 14)]
    degree <- levels(curVar)[c(8:10, 12, 13, 15, 16)]
    sapply(curVar, function(x) {
        if (x %in% noDegree) {
            newVar <- "No degree"
        } else if (x %in% degree) {
            newVar <- "Degree"
        } else {
            newVar <- "College no degree"
        }
    })
}

train$degree <- factor(sortDegree(train$education, train$degree))
test$degree <- factor(sortDegree(test$education, test$degree))
```

### Identifying workers

The class of worker is interesting and could be more complete with an additional level for non-working people.

```{r}
levels(train$class.of.worker) <- c(levels(train$class.of.worker), "Non worker")
levels(test$class.of.worker) <- c(levels(test$class.of.worker), "Non worker")

train$class.of.worker[is.na(train$class.of.worker)] <- "Non worker"
test$class.of.worker[is.na(test$class.of.worker)] <- "Non worker"
```

On the other hand, being enrolled in education at that time can also impact the incomes. Let's create a `Student` variable.

```{r}
train$isStudent[is.na(train$enroll.in.edu.inst.last.wk)] <- "Non post-graduate student"
train$isStudent[!is.na(train$enroll.in.edu.inst.last.wk)] <- "Post-graduate student"
train$isStudent <- factor(train$isStudent)

test$isStudent[is.na(test$enroll.in.edu.inst.last.wk)] <- "Non post-graduate student"
test$isStudent[!is.na(test$enroll.in.edu.inst.last.wk)] <- "Post-graduate student"
test$isStudent <- factor(test$isStudent)
```

Now we differentiate levels based on the `Wage per hour` variable.

```{r}
sliceWage <- function(curVar, newVar) {
    sapply(curVar, function(x) {
        if (x < 20) {
            newVar <- "Nothing"
        } else if (x %in% 20:585) {
            newVar <- "20 to 585"
        } else if (x %in% 586:800) {
            newVar <- "586 to 800"
        } else if (x %in% 801:1200) {
            newVar <- "801 to 1200"
        } else {
            newVar <- "1201+"
        }
    })
}

train$wageClass <- factor(sliceWage(train$wage.per.hour, train$wageClass))
test$wageClass <- factor(sliceWage(test$wage.per.hour, test$wageClass))
```

And I finally convert the number of weeks worked in a year into a factor.

```{r}
train$weeks.worked.in.year <- factor(train$weeks.worked.in.year)
test$weeks.worked.in.year <- factor(test$weeks.worked.in.year)
```

### Counting gains

There are three variables that could strongly impact the income that are the different sources of gains or losses. To get a general idea of a person's status, I take the capital gains or losses and dividends to compute to know whether the trend is positive or negative.

```{r}
train$extGains <- train$capital.gains - train$capital.losses + train$dividends.from.stocks
test$extGains <- test$capital.gains - test$capital.losses + test$dividends.from.stocks

compGains <- cleanIncome <- function(curVar) {
    sapply(curVar, function(x) {
        if (x == 0) {
            curVar <- "Null" 
        } else if (x > 0) {
            curVar <- "Positive"
        } else {
            curVar <- "Negative"
        }
    })
}

train$extGains <- factor(compGains(train$extGains))
test$extGains <- factor(compGains(test$extGains))
```

### Looking at householders

I graph a barplot to observe any pattern with regards of the households details. 

```{r}
ggplot(train, aes(x = detailed.household.summary.in.household, fill = incomes)) + 
    geom_bar() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    xlab("Detailed household") +
    ylab("Count") +
    ggtitle("Relationship between householders and incomes")
```

Spotting householders or householders' spouses seem to be a good point to help us predict the income. I just would llike to modify the variable's name, which is long at the moment.

```{r}
names(train)[24] <- "householdSummary"
names(test)[24] <- "householdSummary"
```

## Observations

Once again, given the short timeframe, I had to make choices and decided not to go further with the feature engineering. Yet there are many things I would have study and here below is an overview.

### Annual income

I noticed that around half of the training dataset is based on 1994 and the other half on 1995. We could think that they are potentially the same population whose data were collected on these two consecutive years.

```{r}
ggplot(train, aes(x = year, fill = incomes)) + 
    geom_bar() + 
    xlab("Year") +
    ylab("Count") +
    ggtitle("Incomes per year")
```

### Focus on migration

The data focuses a lot on the migration aspect. I noticed that some people who were born in specific countries (out of the USA) are more likely to have a 50k+ income like Hungary, Jamaica or Trinidad & Tobago.

### Closer relationships

There are many information crossed in multiple variables. I am quite sure that mixing some other variables could have been interesting to be even more accurate - people who have children, the number of children per household, where they live based on the migration code, and so on...

### Missing values

I replaced the "Not in universe" values with NAs but both are different. "Not in universe" means that the respondant was not concerned by the question asked. 
I could have study the real NAs and see whether it would have been relevant to impute the missing values.

# Model Selection

We want to predict the categorical outcome `incomes` and the data is labeled, meaning we would better work on classification methods. 

## Preping training data

### Final cleaning

I now need to choose the right variables to build my models. Reminder: I also have to remove the `instance.weight` variable as said in the text documentation.

```{r}
keepVar <- c(8, 11:13, 20, 24, 31, 36, 39, 40:47)
#  [1] "marital.stat"                    "race"                            "hispanic.origin"                
#  [4] "sex"                             "tax.filer.stat"                  "householdSummary"               
#  [7] "num.persons.worked.for.employer" "citizenship"                     "veterans.benefits"              
# [10] "weeks.worked.in.year"            "year"                            "incomes"                        
# [13] "ageType"                         "degree"                          "isStudent"                      
# [16] "wageClass"                       "extGains"  
```

I need to make sure all variables' classes are correct.

```{r}
train$marital.stat <- factor(train$marital.stat)
train$race <- factor(train$race)
train$hispanic.origin <- factor(train$hispanic.origin)
train$sex <- factor(train$sex)
train$tax.filer.stat <- factor(train$tax.filer.stat)
train$householdSummary <- factor(train$householdSummary)


for (i in 1:length(test) ) {
    colName <- names(test)[i]
    testType <- class(test[, colName])
    trainType <- class(train[, colName])
    if (trainType != "NULL" && testType != trainType) {
        if (trainType == "factor") {
            test[, colName] <- factor(test[, colName])
        } else {
            test[, colName] <- as.integer(test[, colName])
        }
    }
}
```

And apply the subsetting.

```{r}
cleanTrain <- train[, keepVar]
cleanTest <- test[, keepVar]
```

### Splitting data

We split the original training dataset into small training and testing sets, comprising respectively 80% and 20% of the observations. We will build our model on `subTrain` and test and asses its quality on `subTest`.

```{r}
set.seed(seed)
inTrain <- createDataPartition(y = cleanTrain$incomes, p = .8, list = FALSE)

subTrain <- cleanTrain[inTrain, -12]
subTrainLabel <- cleanTrain[inTrain, 12]

subTest <- cleanTrain[-inTrain, -12]
subTestLabel <- cleanTrain[-inTrain, 12]

dim(subTrain); dim(subTest)
```

### Cross-validation parameters

We train our model using the `caret` package. This allows me to keep the same general control parameters and to use the same approach for the models I test.

```{r}
tControl <- trainControl(method = "repeatedcv", 
                         number = 5, 
                         repeats = 2,
                         search = "grid")
```

## Simple decision tree

### Training model

```{r}
treeGrid <- expand.grid(cp = 0.0004542701)
```

```{r, cache = TRUE}
set.seed(seed)
require(e1071)

classTree <- train(x = subTrain,
                   y = subTrainLabel,
                   method = "rpart",
                   trControl = tControl,
                   tuneLength = 5)

print(classTree)
```

### Checking predictions

Let's see how accurate it is on the pre-final test dataset.

```{r}
treeModel <- predict.train(classTree, newdata = subTest)
## Accuracy : 0.9424 Kappa : 0.3329

confusionMatrix(treeModel, subTestLabel)
```

The accuracy does not look bad with 94%.

### Variables importance

```{r}
treeVarImp <- varImp(classTree)

dotPlot(treeVarImp)
```

## Random Forest

Same approach for this famous model except that I have added two tuning parameters to the Random Forest algorithm: `mtry`and `ntree`. 

```{r, cache = TRUE}
set.seed(seed)
rfGrid <- expand.grid(mtry = )

rf <- train(x = subTrain,
            y = subTrainLabel,
            method = "rf",
            trControl = tControl,
            tuneLength = 5,
            ntree = ,
            tuneGrid = rfGrid)
```

These are the results based on the training set.

```{r}
print(rf)
```

### Checking predictions

Let's see how accurate it is on the pre-final test dataset.

```{r}
rfModel <- predict.train(classTree, newdata = subTest)

confusionMatrix(rfModel, subTestLabel)
```

The accuracy does not look bad with 94%.

### Variables importance

```{r}
rfVarImp <- varImp(rf)

dotPlot(rfVarImp)
```

# Outcome prediction

## Preping test dataset

Now that I have selected my best model, I need to separate the outcome from the rest of the dataset.

```{r}
finalTest <- cleanTest[, -cleanTest$incomes]
finalTestLabel <- finalTest[, cleanTest$incomes]
```

## Final predictions

Finally we can try out the selected model on the final test dataset.

```{r}
rfModelPred <- predict.train(rfModel, newdata = finalTest)
```

## Comparison

```{r}
confusionMatrix(rfModelPred, finalTestLabel)
```

# Challenges

## Short timeframe

My biggest challenge was to complete the exercise within a day. The points that takes me time are:
- Reading the documentation several times to anticipate some questions I might have later on;
- Exploring and cleaning the data as I graph many plots and observe the data again and again;
- Waiting for the models to be trained.

## Sacrifying variables

I knew I could not complete a work as thorough I would have liked. So I had to make 'sacrifices' and choose the variables I had to work on and the ones I had to leave. 
I took the variables that needed some feature engineering and that are accessible. Even though I ended up with this report, I know I could make a more thorough analysis.

